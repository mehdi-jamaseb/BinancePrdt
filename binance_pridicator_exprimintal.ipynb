{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "binance pridicator exprimintal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyhdJouVOxa5HWI21WmjXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-jamaseb/BinancePrdt/blob/master/binance_pridicator_exprimintal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApTJ1hGM-9hM",
        "colab_type": "text"
      },
      "source": [
        "#In the name of God\n",
        "###imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OraeVnKN-4F7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "bf4bfc32-681a-4553-b18b-d416c9069e8a"
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import os.path\n",
        "import time\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Activation, Dense, Dropout, LSTM, Convolution1D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.matlib\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from google.colab import drive\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIKJalDIeo4W",
        "colab_type": "text"
      },
      "source": [
        "###initilize parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W19YvrAsepQ4",
        "colab_type": "code",
        "outputId": "7cd9cc49-d4af-4071-a75a-638d0dd15235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "drive.mount('/content/drive',force_remount=True)\n",
        "np.random.seed(42)\n",
        "samples       = 1000\n",
        "kandel        = '5m'\n",
        "symbol        = 'BTCUSDT'\n",
        "filename      = '/content/drive/My Drive/data/bnb/%s-%s-data.csv' % (symbol,kandel)\n",
        "df            = pd.read_csv(filename)\n",
        "dataCols      = ['open','close','low','high','volume']\n",
        "zeroBaseCols  = [True,True,True,True,False]\n",
        "df.set_index('timestamp', inplace=True)\n",
        "df            = df.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
        "df.index      = df.index.astype(str)\n",
        "\n",
        "if samples>0:\n",
        "  df          = df.loc[df['volume']>0.001,dataCols].tail(samples)\n",
        "else:\n",
        "  df          = df.loc[df['volume']>0.001,dataCols]\n",
        "outputs       = pd.DataFrame(data=['close','high'])\n",
        "window_len    = 99\n",
        "test_size     = 0.2\n",
        "zero_base     = True\n",
        "modelNames    = ['LSTM1','LSTM2']\n",
        "print(df.tail(5))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "                        open    close      low     high      volume\n",
            "timestamp                                                          \n",
            "2020-02-10 14:05:00  9815.67  9841.08  9815.24  9843.89  177.836224\n",
            "2020-02-10 14:10:00  9841.91  9843.72  9838.31  9852.27  193.570387\n",
            "2020-02-10 14:15:00  9846.04  9839.00  9837.01  9850.60  174.423399\n",
            "2020-02-10 14:20:00  9838.94  9841.59  9835.30  9845.02   28.681992\n",
            "2020-02-10 14:20:00  9838.94  9831.48  9827.89  9845.02   52.540787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_hZVC8PefkG",
        "colab_type": "text"
      },
      "source": [
        "###Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hg3h9DTeezW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainTestSplit(df, test_size=0.2):    \n",
        "  split_row = len(df) - int(test_size * len(df))\n",
        "  train_data = df.iloc[:split_row]        \n",
        "  test_data = df.iloc[split_row:]    \n",
        "  return train_data, test_data\n",
        "def linePlot(line1, line2, label1=None, label2=None, title='', lw=2):    \n",
        "  fig, ax = plt.subplots(1, figsize=(13, 7))    \n",
        "  ax.plot(line1, label=label1, linewidth=lw)    \n",
        "  ax.plot(line2, label=label2, linewidth=lw)    \n",
        "  ax.set_ylabel('price [USDT]', fontsize=14)\n",
        "  ax.set_title(title, fontsize=16)\n",
        "  ax.legend(loc='best', fontsize=16)\n",
        "def normaliseZeroBase(df):\n",
        "  return df / df.iloc[0] - 1\n",
        "def normaliseMinMax(df):\n",
        "    return (df - df['low'].min()) / (df['high'].max() - df['low'].min())\n",
        "def extractWindowData(df, window_len=5, zero_base=True):\n",
        "  window_data = []    \n",
        "  #start_time = time.time()\n",
        "  for idx in range(len(df) - window_len):        \n",
        "    tmp           = df[idx: (idx + window_len)].copy()\n",
        "    if zero_base:\n",
        "      tmp         = normaliseZeroBase(tmp)\n",
        "    window_data.append(tmp.values)\n",
        "    #if (idx % 10000)==0:\n",
        "    #  print(\"--- extract iteration(%d) %s seconds ---\" % (idx,(time.time() - start_time)))    \n",
        "    #  start_time = time.time()\n",
        "  return np.array(window_data)\n",
        "def extractX(df,outputs, window_len=5, zero_base=True,isTest=False):\n",
        "    k=0\n",
        "    x = np.zeros((len(df)-window_len,window_len,len(df.columns)))\n",
        "    for i in range (window_len):    \n",
        "        x[:,i,:] = df.iloc[i:-(window_len-i),:].values    \n",
        "        if zero_base:\n",
        "            if i!=0:\n",
        "                x[:,i,:] = x[:,i,:]/x[:,0,:]-1        \n",
        "        k = k+ len(df.columns)\n",
        "    if zero_base:\n",
        "      x[:,0,:] =0;  \n",
        "    if isTest:\n",
        "      return x\n",
        "    else:\n",
        "      return x[:-len(outputs)]\n",
        "def extractY(df,outputs,window_len,zero_base,isTest=False):\n",
        "    nCol  = outputs.count().sum()\n",
        "    y     = np.zeros((len(df)-window_len,nCol))\n",
        "    k     = 0;\n",
        "    for i in range(len(outputs)):\n",
        "        for j in range(len(outputs.columns)):\n",
        "          if outputs.iloc[i,j]!=None:\n",
        "            if i==0:\n",
        "                y[:,k]  = df[outputs.iloc[i,j]][(window_len+i):].values\n",
        "            else:\n",
        "                y[:-i,k]= df[outputs.iloc[i,j]][(window_len+i):].values        \n",
        "            if zero_base:\n",
        "              y[:,k] = y[:,k] / df[outputs.iloc[i,j]][:-window_len].values -1\n",
        "            k = k+1\n",
        "    if isTest:\n",
        "      return y\n",
        "    else:\n",
        "      return y[:-len(outputs),:]\n",
        "#def pridiction(X,model):\n",
        "\n",
        "def createDatasets(train_data,test_data, window_len=10, zero_base=True):  \n",
        "    X_train   = extractX(train_data,outputs, window_len, zero_base)    \n",
        "    X_test    = extractX(test_data, outputs,window_len, zero_base)    \n",
        "    y_train   = extractY(train_data,outputs, window_len, zero_base)\n",
        "    y_test    = extractY(test_data,outputs, window_len, zero_base)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "def prepairData(df,target_col, window_len=10, zero_base=True, test_size=0.2,recreate=False):\n",
        "  datasetFiles = ['X_train','X_test','y_train','y_test']\n",
        "  recreateFile = recreate;\n",
        "  outputsSize  = sum(outputs.count())\n",
        "  for fname in datasetFiles:    \n",
        "    f = '/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % (fname,symbol, window_len,kandel,outputsSize)\n",
        "    if not os.path.isfile(f): \n",
        "      recreateFile=True\n",
        "      break\n",
        "  if recreateFile:\n",
        "    print('Create Datasets ')  \n",
        "    train, test  = trainTestSplit(df, test_size=test_size)    \n",
        "    X_train, X_test, y_train, y_test = createDatasets(train,test, target_col, window_len=window_len, zero_base=zero_base)  \n",
        "    train.to_pickle('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('train',symbol, window_len,kandel,outputsSize))  \n",
        "    test.to_pickle ('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('test' ,symbol, window_len,kandel,outputsSize))   \n",
        "    np.save('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('X_train',symbol, window_len,kandel,outputsSize),X_train)  \n",
        "    np.save('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('X_test' ,symbol, window_len,kandel,outputsSize),X_test)  \n",
        "    np.save('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('y_train',symbol, window_len,kandel,outputsSize),y_train)  \n",
        "    np.save('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('y_test' ,symbol, window_len,kandel,outputsSize),y_test)\n",
        "  else:\n",
        "    print('Load Datasets ')\n",
        "    train   = pd.read_pickle('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('train',symbol, window_len,kandel,outputsSize))\n",
        "    test    = pd.read_pickle('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('test' ,symbol, window_len,kandel,outputsSize))\n",
        "    X_train = np.load('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('X_train',symbol, window_len,kandel,outputsSize))\n",
        "    X_test  = np.load('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('X_test' ,symbol, window_len,kandel,outputsSize))\n",
        "    y_train = np.load('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('y_train',symbol, window_len,kandel,outputsSize))\n",
        "    y_test  = np.load('/content/drive/My Drive/data/bnb/%s-%s-w%d-%s-%d.npy' % ('y_test' ,symbol, window_len,kandel,outputsSize))\n",
        "  return train, test, X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD73A1WQW_Qp",
        "colab_type": "text"
      },
      "source": [
        "###models build functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORokpM_FXGPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = ['mse']\n",
        "def build_lstm_1_model(input_data, outputs, neurons=100, activ_func='linear', dropout=0.2, loss='mse', optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(neurons, input_shape=(input_data.shape[1], input_data.shape[2])))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(units=outputs.count().sum()))\n",
        "    model.add(Activation(activ_func))\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "    return model\n",
        "def build_lstm_2_model(input_data, outputs, neurons=20, activ_func='linear', dropout=0.2, loss='mse', optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(neurons, input_shape=(input_data.shape[1], input_data.shape[2]), return_sequences=True))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(LSTM(neurons, return_sequences=True))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(LSTM(neurons))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(units=outputs.count().sum(), activation=activ_func))\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "    return model\n",
        "def getBuildedModel(X_train,modelName,outputs):\n",
        "    if modelName == modelNames[0]:        \n",
        "        epochs        = 20\n",
        "        batchSize     = 256\n",
        "        model         = build_lstm_1_model(X_train, outputs, neurons=200, dropout=0.2, loss='mse', optimizer='adam')\n",
        "    elif modelName == modelNames[1]:        \n",
        "        epochs        = 100\n",
        "        batchSize     = 256\n",
        "        model         = build_lstm_2_model(X_train, outputs, neurons=20, dropout=0.2, loss='mse', optimizer='adam')    \n",
        "    return epochs, batchSize, model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvAVfBLhkmad",
        "colab_type": "text"
      },
      "source": [
        "###data visualation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLjVdmJqgWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test  = trainTestSplit(df, test_size=test_size)    \n",
        "X_train, X_test, y_train, y_test = createDatasets(train,test, window_len=window_len, zero_base=zero_base)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_hR6pqoOyHg",
        "colab_type": "text"
      },
      "source": [
        "###Data visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03WTJmZbkwpf",
        "colab_type": "text"
      },
      "source": [
        "###Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXfeW8m3bqnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9baba259-2b4b-4513-bd9e-59d0011b447d"
      },
      "source": [
        "k           = 0\n",
        "models      = []\n",
        "histories   = []\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "colors = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2','#7f7f7f','#bcbd22','#17becf','#1a55FF']\n",
        "\n",
        "for iter in range(len(modelNames)):\n",
        "  backUpFile    = '/content/drive/My Drive/data/bnb/%s-%dw.hdf5'% (modelNames[iter],window_len)\n",
        "  metaDataFile  = '/content/drive/My Drive/data/bnb/%s-%dw-meta.npy'% (modelNames[iter],window_len)\n",
        "  checkPointer  = ModelCheckpoint(filepath=backUpFile,save_best_only=True,monitor='loss')  \n",
        "  erStop        = EarlyStopping(monitor='loss', mode='auto',patience=5)\n",
        "  \n",
        "  if not os.path.isfile(backUpFile): \n",
        "    print ('build %s the model'% modelNames[iter])\n",
        "    epochs,batchSize,model    = getBuildedModel(X_train,modelNames[iter],outputs)    \n",
        "    np.save(metaDataFile,[epochs,batchSize])\n",
        "    h        = model.fit( X_train, y_train,validation_data=(X_test,y_test), epochs=epochs, batch_size=batchSize, verbose=1, shuffle=True, callbacks=[checkPointer,erStop])\n",
        "    models.append(model)\n",
        "    histories.append (h)\n",
        "  else:\n",
        "    print ('load %s the model'% modelNames[iter])\n",
        "    epochs, batchSize = np.load(metaDataFile)\n",
        "    model     = load_model(backUpFile)    \n",
        "    h         = model.fit( X_train, y_train, validation_data=(X_test,y_test),epochs=epochs, batch_size=batchSize, verbose=1, shuffle=True, callbacks=[checkPointer,erStop])\n",
        "    models.append(model)    \n",
        "  #ax.plot( h.history['loss'], color=colors[iter*2],label=modelNames[iter]+'_train')\n",
        "  ax.plot( h.history['val_loss'], color=colors[iter],label=modelNames[iter]+'_test')\n",
        "  ax.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build LSTM1 the model\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 699 samples, validate on 99 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "699/699 [==============================] - 11s 15ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 2/20\n",
            "699/699 [==============================] - 0s 703us/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 3/20\n",
            "699/699 [==============================] - 0s 706us/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 4/20\n",
            "699/699 [==============================] - 1s 783us/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 5/20\n",
            "699/699 [==============================] - 1s 742us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 6/20\n",
            "699/699 [==============================] - 1s 794us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 7/20\n",
            "699/699 [==============================] - 1s 780us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.8708e-04 - val_mean_squared_error: 8.8708e-04\n",
            "Epoch 8/20\n",
            "699/699 [==============================] - 1s 883us/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 4.6139e-04 - val_mean_squared_error: 4.6139e-04\n",
            "Epoch 9/20\n",
            "699/699 [==============================] - 1s 814us/step - loss: 8.4420e-04 - mean_squared_error: 8.4420e-04 - val_loss: 8.3780e-04 - val_mean_squared_error: 8.3780e-04\n",
            "Epoch 10/20\n",
            "699/699 [==============================] - 1s 716us/step - loss: 8.1204e-04 - mean_squared_error: 8.1204e-04 - val_loss: 6.4883e-04 - val_mean_squared_error: 6.4883e-04\n",
            "Epoch 11/20\n",
            "699/699 [==============================] - 1s 791us/step - loss: 8.8065e-04 - mean_squared_error: 8.8065e-04 - val_loss: 8.2181e-04 - val_mean_squared_error: 8.2181e-04\n",
            "Epoch 12/20\n",
            "699/699 [==============================] - 1s 852us/step - loss: 7.3548e-04 - mean_squared_error: 7.3548e-04 - val_loss: 9.1930e-04 - val_mean_squared_error: 9.1930e-04\n",
            "Epoch 13/20\n",
            "699/699 [==============================] - 1s 807us/step - loss: 5.9506e-04 - mean_squared_error: 5.9506e-04 - val_loss: 4.1118e-04 - val_mean_squared_error: 4.1118e-04\n",
            "Epoch 14/20\n",
            "699/699 [==============================] - 1s 742us/step - loss: 6.3764e-04 - mean_squared_error: 6.3764e-04 - val_loss: 5.2469e-04 - val_mean_squared_error: 5.2469e-04\n",
            "Epoch 15/20\n",
            "699/699 [==============================] - 1s 749us/step - loss: 5.9411e-04 - mean_squared_error: 5.9411e-04 - val_loss: 7.0891e-04 - val_mean_squared_error: 7.0891e-04\n",
            "Epoch 16/20\n",
            "699/699 [==============================] - 0s 682us/step - loss: 5.7853e-04 - mean_squared_error: 5.7853e-04 - val_loss: 6.6524e-04 - val_mean_squared_error: 6.6524e-04\n",
            "Epoch 17/20\n",
            "699/699 [==============================] - 0s 674us/step - loss: 4.9171e-04 - mean_squared_error: 4.9171e-04 - val_loss: 1.0567e-04 - val_mean_squared_error: 1.0567e-04\n",
            "Epoch 18/20\n",
            "699/699 [==============================] - 1s 716us/step - loss: 5.3992e-04 - mean_squared_error: 5.3992e-04 - val_loss: 1.0395e-04 - val_mean_squared_error: 1.0395e-04\n",
            "Epoch 19/20\n",
            "699/699 [==============================] - 1s 783us/step - loss: 5.0539e-04 - mean_squared_error: 5.0539e-04 - val_loss: 3.4446e-04 - val_mean_squared_error: 3.4446e-04\n",
            "Epoch 20/20\n",
            "699/699 [==============================] - 1s 859us/step - loss: 4.8813e-04 - mean_squared_error: 4.8813e-04 - val_loss: 5.7204e-04 - val_mean_squared_error: 5.7204e-04\n",
            "build LSTM2 the model\n",
            "Train on 699 samples, validate on 99 samples\n",
            "Epoch 1/100\n",
            "699/699 [==============================] - 3s 5ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
            "Epoch 2/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.9178e-04 - mean_squared_error: 7.9178e-04 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
            "Epoch 3/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.7728e-04 - mean_squared_error: 6.7728e-04 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 4/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 5.4000e-04 - mean_squared_error: 5.4000e-04 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 5/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 3.9752e-04 - mean_squared_error: 3.9752e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
            "Epoch 6/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 3.1317e-04 - mean_squared_error: 3.1317e-04 - val_loss: 8.7256e-04 - val_mean_squared_error: 8.7256e-04\n",
            "Epoch 7/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 3.0873e-04 - mean_squared_error: 3.0873e-04 - val_loss: 7.2354e-04 - val_mean_squared_error: 7.2354e-04\n",
            "Epoch 8/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 2.7658e-04 - mean_squared_error: 2.7658e-04 - val_loss: 8.3556e-04 - val_mean_squared_error: 8.3556e-04\n",
            "Epoch 9/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 2.0985e-04 - mean_squared_error: 2.0985e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 10/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 1.7952e-04 - mean_squared_error: 1.7952e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 11/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.7920e-04 - mean_squared_error: 1.7920e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 12/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.7750e-04 - mean_squared_error: 1.7750e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 13/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.6443e-04 - mean_squared_error: 1.6443e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 14/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.4697e-04 - mean_squared_error: 1.4697e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 15/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.3426e-04 - mean_squared_error: 1.3426e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 16/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.4687e-04 - mean_squared_error: 1.4687e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 17/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.2725e-04 - mean_squared_error: 1.2725e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 18/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 1.2506e-04 - mean_squared_error: 1.2506e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 19/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 1.2067e-04 - mean_squared_error: 1.2067e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 20/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 1.1999e-04 - mean_squared_error: 1.1999e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 21/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.1597e-04 - mean_squared_error: 1.1597e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 22/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.1594e-04 - mean_squared_error: 1.1594e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 23/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.0967e-04 - mean_squared_error: 1.0967e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 24/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.0352e-04 - mean_squared_error: 1.0352e-04 - val_loss: 9.6933e-04 - val_mean_squared_error: 9.6933e-04\n",
            "Epoch 25/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 1.0800e-04 - mean_squared_error: 1.0800e-04 - val_loss: 9.9448e-04 - val_mean_squared_error: 9.9448e-04\n",
            "Epoch 26/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 9.5326e-05 - mean_squared_error: 9.5326e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 27/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 9.8974e-05 - mean_squared_error: 9.8974e-05 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 28/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 9.6106e-05 - mean_squared_error: 9.6106e-05 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 29/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 9.3767e-05 - mean_squared_error: 9.3767e-05 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 30/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 9.6222e-05 - mean_squared_error: 9.6222e-05 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 31/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 9.3484e-05 - mean_squared_error: 9.3484e-05 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 32/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 9.0750e-05 - mean_squared_error: 9.0750e-05 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 33/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 9.0632e-05 - mean_squared_error: 9.0632e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 34/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 8.7361e-05 - mean_squared_error: 8.7361e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 35/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 8.7698e-05 - mean_squared_error: 8.7698e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 36/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 8.0548e-05 - mean_squared_error: 8.0548e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 37/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 8.4032e-05 - mean_squared_error: 8.4032e-05 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
            "Epoch 38/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 8.1241e-05 - mean_squared_error: 8.1241e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 39/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 8.3463e-05 - mean_squared_error: 8.3463e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 40/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 8.1118e-05 - mean_squared_error: 8.1118e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 41/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 7.8649e-05 - mean_squared_error: 7.8649e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 42/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.9172e-05 - mean_squared_error: 7.9172e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 43/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 8.3359e-05 - mean_squared_error: 8.3359e-05 - val_loss: 9.9776e-04 - val_mean_squared_error: 9.9776e-04\n",
            "Epoch 44/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 8.0864e-05 - mean_squared_error: 8.0864e-05 - val_loss: 9.9769e-04 - val_mean_squared_error: 9.9769e-04\n",
            "Epoch 45/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.9262e-05 - mean_squared_error: 7.9262e-05 - val_loss: 9.9240e-04 - val_mean_squared_error: 9.9240e-04\n",
            "Epoch 46/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.5811e-05 - mean_squared_error: 7.5811e-05 - val_loss: 9.8281e-04 - val_mean_squared_error: 9.8281e-04\n",
            "Epoch 47/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.5474e-05 - mean_squared_error: 7.5474e-05 - val_loss: 9.8154e-04 - val_mean_squared_error: 9.8154e-04\n",
            "Epoch 48/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.5566e-05 - mean_squared_error: 7.5566e-05 - val_loss: 9.8120e-04 - val_mean_squared_error: 9.8120e-04\n",
            "Epoch 49/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.3024e-05 - mean_squared_error: 7.3024e-05 - val_loss: 9.7016e-04 - val_mean_squared_error: 9.7016e-04\n",
            "Epoch 50/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.0917e-05 - mean_squared_error: 7.0917e-05 - val_loss: 9.9686e-04 - val_mean_squared_error: 9.9686e-04\n",
            "Epoch 51/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.1438e-05 - mean_squared_error: 7.1438e-05 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
            "Epoch 52/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 7.0585e-05 - mean_squared_error: 7.0585e-05 - val_loss: 9.9236e-04 - val_mean_squared_error: 9.9236e-04\n",
            "Epoch 53/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 7.2145e-05 - mean_squared_error: 7.2145e-05 - val_loss: 9.6037e-04 - val_mean_squared_error: 9.6037e-04\n",
            "Epoch 54/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.9957e-05 - mean_squared_error: 6.9957e-05 - val_loss: 9.3283e-04 - val_mean_squared_error: 9.3283e-04\n",
            "Epoch 55/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 6.8346e-05 - mean_squared_error: 6.8346e-05 - val_loss: 9.3956e-04 - val_mean_squared_error: 9.3956e-04\n",
            "Epoch 56/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.7220e-05 - mean_squared_error: 6.7220e-05 - val_loss: 9.4981e-04 - val_mean_squared_error: 9.4981e-04\n",
            "Epoch 57/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.6193e-05 - mean_squared_error: 6.6193e-05 - val_loss: 9.5429e-04 - val_mean_squared_error: 9.5429e-04\n",
            "Epoch 58/100\n",
            "699/699 [==============================] - 1s 2ms/step - loss: 7.0111e-05 - mean_squared_error: 7.0111e-05 - val_loss: 9.3040e-04 - val_mean_squared_error: 9.3040e-04\n",
            "Epoch 59/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.7640e-05 - mean_squared_error: 6.7640e-05 - val_loss: 9.3473e-04 - val_mean_squared_error: 9.3473e-04\n",
            "Epoch 60/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.7653e-05 - mean_squared_error: 6.7653e-05 - val_loss: 9.3115e-04 - val_mean_squared_error: 9.3115e-04\n",
            "Epoch 61/100\n",
            "699/699 [==============================] - 2s 3ms/step - loss: 6.4545e-05 - mean_squared_error: 6.4545e-05 - val_loss: 9.2933e-04 - val_mean_squared_error: 9.2933e-04\n",
            "Epoch 62/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.1339e-05 - mean_squared_error: 6.1339e-05 - val_loss: 9.2392e-04 - val_mean_squared_error: 9.2392e-04\n",
            "Epoch 63/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.2890e-05 - mean_squared_error: 6.2890e-05 - val_loss: 9.3602e-04 - val_mean_squared_error: 9.3602e-04\n",
            "Epoch 64/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.1976e-05 - mean_squared_error: 6.1976e-05 - val_loss: 9.0946e-04 - val_mean_squared_error: 9.0946e-04\n",
            "Epoch 65/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.2473e-05 - mean_squared_error: 6.2473e-05 - val_loss: 8.5112e-04 - val_mean_squared_error: 8.5112e-04\n",
            "Epoch 66/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.1695e-05 - mean_squared_error: 6.1695e-05 - val_loss: 8.7768e-04 - val_mean_squared_error: 8.7768e-04\n",
            "Epoch 67/100\n",
            "699/699 [==============================] - 2s 2ms/step - loss: 6.2764e-05 - mean_squared_error: 6.2764e-05 - val_loss: 9.1404e-04 - val_mean_squared_error: 9.1404e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuImZgoSlqXM",
        "colab_type": "text"
      },
      "source": [
        "###Test Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXP3Qgh-6Pm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testModel (testData,model):\n",
        "    X         = extractX(testData,outputs,window_len,zero_base,isTest=True)\n",
        "    Y         = extractX(testData,outputs,window_len,zero_base,isTest=True)\n",
        "    predZ     = model.predict(X).squeeze()\n",
        "    predR     = predZ*0\n",
        "    colName   = []\n",
        "    k= 0\n",
        "    if zero_base:\n",
        "      for i in range(len(outputs)):\n",
        "        for j in range(len(outputs.columns)):\n",
        "          if outputs.iloc[i,j]!=None:\n",
        "            c = outputs.iloc[i,j] +'+'+ str(i+1)\n",
        "            colName.append(c)\n",
        "            predR[:,k] =  testData[outputs.iloc[i,j]][:-window_len].values * (predZ[:,k]+1)\n",
        "            k = k+1\n",
        "    return pd.DataFrame(predR,index = testData.iloc[window_len:].index,columns=colName)\n",
        "\n",
        "pr0 = testModel(test,models[0])\n",
        "pr1 = testModel(test,models[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzZo1UGJl2Bp",
        "colab_type": "text"
      },
      "source": [
        "###Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5M-nyAYl66G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "9e0a9a53-1967-4f6f-8cf7-ba599cc8570b"
      },
      "source": [
        "realRes = extractY(test,outputs,window_len,zero_base=False,isTest=True)\n",
        "diff1  = (realRes-pr0).head(len(realRes)-len(outputs))\n",
        "diff2  = (realRes-pr1).head(len(realRes)-len(outputs))\n",
        "print('mean error:')\n",
        "print(abs(diff1).mean())\n",
        "print('---')\n",
        "print(abs(diff2).mean())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean error:\n",
            "close+1    147.284463\n",
            "high+2     211.808459\n",
            "dtype: float64\n",
            "---\n",
            "close+1    282.634032\n",
            "high+2     292.048062\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}